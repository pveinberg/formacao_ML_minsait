{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TITANIC DATASET - ML - RANDOM FOREST\n",
    "===================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import mlflow\n",
    "import pickle\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "\n",
    "from datetime import datetime\n",
    "from functions import get_metrics\n",
    "\n",
    "from matplotlib import pyplot as plt \n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXPERIMENT_TITLE = \"Titanic Dataset Analyzes\"\n",
    "\n",
    "run_description = \"\"\"\n",
    "### Descrição\n",
    "\n",
    "Implementação usando [Random Forest](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html)\n",
    "\"\"\"\n",
    "\n",
    "tags = {\n",
    "    \"date\": datetime.now(),\n",
    "    \"author\": \"Pablo Veinberg\",\n",
    "    \"version\": 1.0,\n",
    "    \"envoronment\": \"local\",\n",
    "    \"mlflow.note.content\": run_description,\n",
    "    \"mlflow.runName\": \"Random Forest\",\n",
    "    \"data_source\": \"./../datasets/silver/train-encoded-not-normalize.parquet\",\n",
    "    \"train_test_dataset\": \"./../datasets/silver/titanic-train-test-data.pkl\"\n",
    "}\n",
    "\n",
    "params = {\n",
    "    \"token\": np.random.randint(10_000,high=99_000),\n",
    "    \"model_params\": {\n",
    "        \"criterion\": [\"gini\", \"entropy\", \"log_loss\"],\n",
    "        \"max_features\": [\"sqrt\", \"log2\", None]\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pablo_veinberg/.local/lib/python3.10/site-packages/mlflow/data/dataset_source_registry.py:143: UserWarning: The specified dataset source can be interpreted in multiple ways: LocalArtifactDatasetSource, LocalArtifactDatasetSource. MLflow will assume that this is a LocalArtifactDatasetSource source.\n",
      "  return _dataset_source_registry.resolve(\n"
     ]
    }
   ],
   "source": [
    "dataset = pd.read_parquet(tags['data_source'])\n",
    "mlflow_dataset = mlflow.data.from_pandas(dataset, \\\n",
    "                                            source=tags['data_source'], \\\n",
    "                                            name=\"Titanic Dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((712, 8), (179, 8), (712,), (179,))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('./../datasets/silver/titanic-train-test-data.pkl', 'rb') as file:\n",
    "    X_train, X_test, y_train, y_test = pickle.load(file)\n",
    "\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Malformed experiment 'mlruns'. Detailed error Yaml file '/home/pablo_veinberg/dev/indra/formacao-machine-learning-minsait-2023/Notebooks/Projeto-Titanic/scripts/mlruns/mlruns/meta.yaml' does not exist.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/pablo_veinberg/.local/lib/python3.10/site-packages/mlflow/store/tracking/file_store.py\", line 302, in search_experiments\n",
      "    exp = self._get_experiment(exp_id, view_type)\n",
      "  File \"/home/pablo_veinberg/.local/lib/python3.10/site-packages/mlflow/store/tracking/file_store.py\", line 395, in _get_experiment\n",
      "    meta = FileStore._read_yaml(experiment_dir, FileStore.META_DATA_FILE_NAME)\n",
      "  File \"/home/pablo_veinberg/.local/lib/python3.10/site-packages/mlflow/store/tracking/file_store.py\", line 1303, in _read_yaml\n",
      "    return _read_helper(root, file_name, attempts_remaining=retries)\n",
      "  File \"/home/pablo_veinberg/.local/lib/python3.10/site-packages/mlflow/store/tracking/file_store.py\", line 1296, in _read_helper\n",
      "    result = read_yaml(root, file_name)\n",
      "  File \"/home/pablo_veinberg/.local/lib/python3.10/site-packages/mlflow/utils/file_utils.py\", line 303, in read_yaml\n",
      "    raise MissingConfigException(f\"Yaml file '{file_path}' does not exist.\")\n",
      "mlflow.exceptions.MissingConfigException: Yaml file '/home/pablo_veinberg/dev/indra/formacao-machine-learning-minsait-2023/Notebooks/Projeto-Titanic/scripts/mlruns/mlruns/meta.yaml' does not exist.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pablo_veinberg/.local/lib/python3.10/site-packages/mlflow/data/pandas_dataset.py:134: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n",
      "  return _infer_schema(self._df)\n"
     ]
    }
   ],
   "source": [
    "mlflow.set_experiment(EXPERIMENT_TITLE)\n",
    "\n",
    "with mlflow.start_run():\n",
    "\n",
    "    # Settings\n",
    "    mlflow.log_input(mlflow_dataset)\n",
    "    mlflow.set_tags(tags)\n",
    "    mlflow.log_params(params)\n",
    "\n",
    "    grid = GridSearchCV(estimator=RandomForestClassifier(), \\\n",
    "                        param_grid=params[\"model_params\"])\n",
    "    grid.fit(X_train, y_train)\n",
    "\n",
    "    model = RandomForestClassifier(**grid.best_params_)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    plot_confusion_matrix_path = f\"./../results/random_forest_{params['token']}.png\"\n",
    "    metrics = get_metrics(y_test, y_pred, plot_confusion_matrix_path, \"Matrix Confusion - Titanic Dataset\")\n",
    "    \n",
    "    mlflow.log_param(\"best_params\", grid.best_params_)\n",
    "    mlflow.log_metrics(metrics)\n",
    "    mlflow.log_artifact(plot_confusion_matrix_path)\n",
    "    \n",
    "mlflow.end_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[98,  7],\n",
       "       [ 7, 67]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Survival|0 = No, 1 = Yes\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O modelo é bom em 93.33% para acertar não sobreviventes\n",
      "Quando acerta, está correto num 93.33%\n",
      "Esta informação foi baseada em 105 registros\n",
      "==================================================\n",
      "O modelo é bom em 90.54% para acertar sobreviventes\n",
      "Quando acerta, está correto num 90.54%\n",
      "Esta informação foi baseada em 74 registros\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "class_report = classification_report(y_test, y_pred, \n",
    "                           output_dict=True)\n",
    "\n",
    "results = class_report['macro avg']\n",
    "\n",
    "\n",
    "# precisão indica quão bom o modelo é para detectar positivos\n",
    "\n",
    "labels = ['não sobreviventes', 'sobreviventes']\n",
    "\n",
    "for key, value in enumerate(labels):\n",
    "    print(f\"O modelo é bom em {round(class_report[str(key)]['precision'] * 100 ,2)}% para acertar {value}\")\n",
    "    print(f\"Quando acerta, está correto num {round(class_report[str(key)]['recall'] * 100 ,2)}%\")\n",
    "    print(f\"Esta informação foi baseada em {round(class_report[str(key)]['support'],0)} registros\")\n",
    "    print(\"=\"*50)\n",
    "\n",
    "# print(f\"O modelo é bom em {round(class_report['0']['precision'] * 100 ,2)}% para acertar não sobreviventes\")\n",
    "# print(f\"Quando acerta, está correto num {round(class_report['0']['recall'] * 100 ,2)}%\")\n",
    "\n",
    "\n",
    "# # recall indica quando a resposta real é sim, quanto o modelo acertou\n",
    "# print(class_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.93      0.93       105\n",
      "           1       0.91      0.91      0.91        74\n",
      "\n",
      "    accuracy                           0.92       179\n",
      "   macro avg       0.92      0.92      0.92       179\n",
      "weighted avg       0.92      0.92      0.92       179\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
